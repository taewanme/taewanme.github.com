<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on taewan.kim 블로그</title>
    <link>http://taewan.kim/tags/spark/</link>
    <description>Recent content in Spark on taewan.kim 블로그</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 26 Apr 2020 01:20:25 +0900</lastBuildDate>
    
	<atom:link href="http://taewan.kim/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[OCI]Spark 개발 환경 구성</title>
      <link>http://taewan.kim/cloud/oci_spark_dev_env/</link>
      <pubDate>Sun, 26 Apr 2020 01:20:25 +0900</pubDate>
      
      <guid>http://taewan.kim/cloud/oci_spark_dev_env/</guid>
      <description>OCI에서 Spark 환경을 구성할 때, Spark 애플리케이션이 사용하는 데이터는 대부분 OCI Object Storage에 저장됩니다. OCI Object Storage는 Map Reduce와 Spark 애플리케이션이 OCI Object Storage에 접근할 수 있도록 HDFS Connector를 제공합니다. HDFS Connector가 구성된 Hadoop Cluster나 Spark Cluster에서 OCI Object Storage를 oci://&amp;hellip; 프로토롤로 접근할 수 있습니다.
최근에 OCI에는 Apache Spark 서비스인 OCI Data Flow가 공개되었습니다. OCI Data Flow에 Spark Job을 등록하면 Spark 클러스터가 배포되고 실행됩니다. 등록된 Job이 종료되면 Spark Cluter를 제거하는 Serverless spark 서비스입니다.</description>
    </item>
    
    <item>
      <title>Spark: Collection의 flatMap을 이용한 비정상 패턴 처리</title>
      <link>http://taewan.kim/post/how_to_process_abnomal_pattern_with_flatmap/</link>
      <pubDate>Fri, 13 Apr 2018 21:59:47 +0900</pubDate>
      
      <guid>http://taewan.kim/post/how_to_process_abnomal_pattern_with_flatmap/</guid>
      <description>스칼라에서 map과 flatMap의 차이점을 파악하고 이해하는 것은 쉽지 않은것 같습니다. 이상 데이터 처리는 두 함수를 차아점을 구분하는 예제로 적합하다고 생가합니다. 이상 데이터 처리 예젤로 두 함수의 의미를 정리하겠습니다.
스칼라에서 컬렉션을 map함수로 변환시킬 때 어떤 것을 걸러 내야 할 때가 있습니다.
val x = List(&amp;quot;taewan 45&amp;quot;, &amp;quot;minsu 6&amp;quot;, &amp;quot;sunny 40&amp;quot;) x.map{ v =&amp;gt; val Array(name, age) = v.split(&amp;quot; &amp;quot;) (name, age.toInt) }  위 코드는 다음과 같이 출력됩니다.
 출력:</description>
    </item>
    
    <item>
      <title>Oracle BDCSCE: 클러스터 생성 </title>
      <link>http://taewan.kim/cloud/stpe_by_step_new_cluster_bdcsce/</link>
      <pubDate>Mon, 31 Jul 2017 11:59:47 +0900</pubDate>
      
      <guid>http://taewan.kim/cloud/stpe_by_step_new_cluster_bdcsce/</guid>
      <description>Oracle Big Data Cloud Service Compute-Edition(이하 Oracle BDCSCE)은 PaaS 형태로 제공되는 Oracle Pubic Cloud의 빅데이터 서비스입니다. 본 문서에서는 Oracle BDCSCE 서비스를 이용하여 하둡 클러스터를 생성하는 절차를 소개합니다.
본 문서는 오라클 클라우드 트라이얼 계정을 사용하여 진행하겠습니다. Oracle BDCSCE 서비스를 이용하여 하둡 클러스터를 생성하기 위해서는 오라클 클라우드 계정이 필요합니다. 오라클 계정이 없으면 다음 문서를 참조하여 실습하기 전에 오라클 클라우드 계정을 만드시기 바랍니다.
 오라클 클라우드 트라이얼 계정 생성 - http://www.oracloud.kr/post/accont/  Oracle BDCSCE 서비스에서 클러스터를 생성하기 위해서는 Oracle Storage CS 정보를 입력해야 합니다.</description>
    </item>
    
    <item>
      <title>Oracle Big Data Cloud Service Compute-Edition</title>
      <link>http://taewan.kim/cloud/bdcsce01/</link>
      <pubDate>Thu, 27 Jul 2017 11:59:47 +0900</pubDate>
      
      <guid>http://taewan.kim/cloud/bdcsce01/</guid>
      <description>빅데이터 기술을 사용하면서 가장 어려운 부분은 오픈소스로 구성된 빅데이터 에코 기술을 설치하고 관리하는 부분입니다. 빅데이터 에코 기술들은 여러 오픈소스 프로젝트로 구성되어 있고, 각 오픈소스 프로젝트는 특정 오픈소스 프로젝트의 버전에 의존성을 갖고 있습니다. 또한, 각 오픈소스는 개별적인 업그레이드 주기를 갖습니다. 여러 오픈소스 프로젝트가 상호 버전 의존성을 갖고 있고, 개별적인 업그레이드 주기를 갖는 기술들로 빅데이터 환경을 구성하고 관리하기 위해서는 많은 노력이 필요합니다. 이 문제를 해결하기 위해서 Cloudera와 Hotonworks는 빅데이터 오픈소스 프로젝트들의 검증된 버전을 모아 패키지로 관리합니다.</description>
    </item>
    
  </channel>
</rss>